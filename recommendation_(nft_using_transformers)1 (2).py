# -*- coding: utf-8 -*-
"""Recommendation (nft using transformers)1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q8u69oZ8AWxL2DiC1A1M4Ew5IlXuZAcK
"""

import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/nft_sales.csv')

df

df.info()

df = df.dropna()

df.info()

df['description'] = df['collection_name'] + ' ' +df['asset_name'] +' '+ df['asset_description'] +' event_time: '+ df['event_time']

df

from transformers import AutoTokenizer, AutoModel
import torch
import torch.nn.functional as F

tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')
model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')

sentences = ['Punk art', 'Digital rabbit cute']

encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')
encoded_input

with torch.no_grad():
       model_output = model(**encoded_input)

model_output

def mean_pooling(model_output, attention_mask):
    token_embeddings = model_output[0]  #First element of model_output contains all token embeddings
    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)

sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])
sentence_embeddings

"""ALREADY INBIULT LIBRARY IN HUGGINGFACE"""

!pip install -U sentence-transformers

from sentence_transformers import SentenceTransformer

model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

from tqdm import tqdm

# Use tqdm inside model.encode by setting show_progress_bar=True
nft_embeddings = model.encode(df['description'].tolist(), show_progress_bar=True)

nft_embeddings

query = "sad music "

from sklearn.metrics.pairwise import cosine_similarity


def get_recommendations(query, embeddings, df, top_n=5):
    query_embedding = model.encode([query])
    similarities = cosine_similarity(query_embedding, nft_embeddings)
    top_indices = similarities[0].argsort()[-top_n:][::-1]
    return df.iloc[top_indices]

recommendations = get_recommendations(query, nft_embeddings, df)

recommendations

import pickle

